{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defeat learners\n",
    "ML for trading Udacity Course exercise\n",
    "\n",
    "More info:\n",
    "https://quantsoftware.gatech.edu/Defeat_learners\n",
    "\n",
    "A transcription of the Udacity Course lectures can be find on https://docs.google.com/document/d/1ELqlnuTSdc9-MDHOkV0uvSY4RmI1eslyQlU9DgOY_jc/edit?usp=sharing\n",
    "\n",
    "Kairosart 2018\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this project you will generate data that you believe will work better for one learner than another. This will test your understanding of the strengths and weaknesses of various learners. The two learners you should aim your datasets at are:\n",
    "\n",
    "    * A decision tree learner with leaf_size = 1 (DTLearner). Note that for testing purposes we will use our implementation of DTLearner\n",
    "    * A LinRegLearner provided as part of the repo.\n",
    "\n",
    "Your data generation should use a random number generator as part of its data generation process. We will pass your generators a random number seed. Whenever the seed is the same you should return exactly the same data set. Different seeds should result in different data sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from copy import deepcopy\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "import math  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  best4LinReg Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best4LinReg(seed=np.random.randint(1000000)):\n",
    "    \"\"\"This function should return a dataset (X and Y) that will work\n",
    "    better for linear regression than decision trees\n",
    "    Parameters: \n",
    "    seed: Random integer used to initialize the pseudo-random number generator. \n",
    "    Whenever the seed is the same, the same data set will be returned. \n",
    "    Different seeds should result in different data sets.\n",
    "    Returns: \n",
    "    X: A numpy ndarray of X values\n",
    "    Y: A numpy 1D array of Y values\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # X and Y should each contain from 10 to 1000 rows\n",
    "    num_rows = np.random.randint(10, 1001)\n",
    "\n",
    "    # X should have from 2 to 10 columns\n",
    "    num_X_cols = np.random.randint(2, 11)\n",
    "\n",
    "    X = np.random.normal(size=(num_rows, num_X_cols))\n",
    "    Y = np.zeros(num_rows)\n",
    "    for col in range(num_X_cols):\n",
    "        Y += X[:, col]\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## best4DT Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best4DT(seed=np.random.randint(1000000)):\n",
    "    \"\"\"This function should return a dataset (X and Y) that will work\n",
    "    better for decision trees than linear regression\n",
    "    Parameters: \n",
    "    seed: Random seed used to initialize the pseudo-random number generator. \n",
    "    Whenever the seed is the same, the same data set will be returned. \n",
    "    Different seeds should result in different data sets.\n",
    "    Returns: \n",
    "    X: A numpy ndarray of X values\n",
    "    Y: A numpy 1D array of Y values\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # X and Y should each contain from 10 to 1000 rows\n",
    "    num_rows = np.random.randint(10, 1001)\n",
    "\n",
    "    # X should have from 2 to 10 columns\n",
    "    num_X_cols = np.random.randint(2, 11)\n",
    "\n",
    "    X = np.random.normal(size=(num_rows, num_X_cols))\n",
    "    Y = np.zeros(num_rows)\n",
    "    for col in range(num_X_cols):\n",
    "        Y += X[:, col] ** 2\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data to fool learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, Y1 = best4LinReg(seed = 5)\n",
    "X2, Y2 = best4DT(seed = 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deductions:\n",
    "\n",
    "    * Does either dataset returned contain fewer or more than the allowed number of samples?\n",
    "    * Does either dataset returned contain fewer or more than the allowed number of dimensions in X?\n",
    "    * When the seed is the same does the best4LinReg dataset generator return the same data?\n",
    "    * When the seed is the same does the best4DT dataset generator return the same data?\n",
    "    * When the seed is different does the best4LinReg dataset generator return different data?\n",
    "    * When the seed is different does the best4DT dataset generator return different data?\n",
    "    * Does the code attempt to import a learner? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples:  877 877\n",
      "Dimensions:  (877, 8) (877, 8)\n",
      "When the seed is the same does the best4LinReg dataset generator return the same data.\n",
      "When the seed is the same does the best4DT dataset generator return the same data.\n"
     ]
    }
   ],
   "source": [
    "# Number of samples\n",
    "print(\"Samples: \", X1.shape[0], X2.shape[0]) \n",
    "\n",
    "# Dimensions\n",
    "print(\"Dimensions: \", X1.shape, X2.shape)\n",
    "\n",
    "# best4LinReg dataset generator\n",
    "print(\"When the seed is the same does the best4LinReg dataset generator return the same data.\")\n",
    "\n",
    "# best4DT dataset generator\n",
    "print(\"When the seed is the same does the best4DT dataset generator return the same data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DTLearner\n",
    "\n",
    "A simple wrapper for Decision Tree regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTLearner(object):\n",
    "\n",
    "    def __init__(self, leaf_size=1, verbose=False, tree=None):\n",
    "        self.leaf_size = leaf_size\n",
    "        self.verbose = verbose\n",
    "        self.tree = deepcopy(tree)\n",
    "        if verbose:\n",
    "            self.get_learner_info()\n",
    "        \n",
    "\n",
    "    def __build_tree(self, dataX, dataY, rootX=[], rootY=[]):\n",
    "        \"\"\"Builds the Decision Tree recursively by choosing the best feature to split on and \n",
    "        the splitting value. The best feature has the highest absolute correlation with dataY. \n",
    "        If all features have the same absolute correlation, choose the first feature. The \n",
    "        splitting value is the median of the data according to the best feature. \n",
    "        If the best feature doesn't split the data into two groups, choose the second best \n",
    "        one and so on; if none of the features does, return leaf\n",
    "        Parameters:\n",
    "        dataX: A numpy ndarray of X values at each node\n",
    "        dataY: A numpy 1D array of Y values at each node\n",
    "        rootX: A numpy ndarray of X values at the parent/root node of the current one\n",
    "        rootY: A numpy 1D array of Y values at the parent/root node of the current one\n",
    "        \n",
    "        Returns:\n",
    "        tree: A numpy ndarray. Each row represents a node and four columns are feature indices \n",
    "        (int type; index for a leaf is -1), splitting values, and starting rows, from the current \n",
    "        root, for its left and right subtrees (if any)\n",
    "        \"\"\"\n",
    "        # Get the number of samples (rows) and features (columns) of dataX\n",
    "        num_samples = dataX.shape[0]\n",
    "        num_feats = dataX.shape[1]\n",
    "        \n",
    "        \n",
    "        # If there is no sample left, return the most common value from the root of current node\n",
    "        if num_samples == 0:\n",
    "            return np.array([-1, Counter(rootY).most_common(1)[0][0], np.nan, np.nan])\n",
    "\n",
    "        # If there are <= leaf_size samples or all data in dataY are the same, return leaf\n",
    "        if num_samples <= self.leaf_size or len(pd.unique(dataY)) == 1:\n",
    "            return np.array([-1, Counter(dataY).most_common(1)[0][0], np.nan, np.nan])\n",
    "    \n",
    "        avail_feats_for_split = list(range(num_feats))\n",
    "\n",
    "        # Get a list of tuples of features and their correlations with dataY\n",
    "        feats_corrs = []\n",
    "        for feat_i in range(num_feats):\n",
    "            abs_corr = abs(pearsonr(dataX[:, feat_i], dataY)[0])\n",
    "            feats_corrs.append((feat_i, abs_corr))\n",
    "        \n",
    "        # Sort the list in descending order by correlation\n",
    "        feats_corrs = sorted(feats_corrs, key=itemgetter(1), reverse=True)\n",
    "\n",
    "        # Choose the best feature, if any, by iterating over feats_corrs\n",
    "        feat_corr_i = 0\n",
    "        while len(avail_feats_for_split) > 0:\n",
    "            best_feat_i = feats_corrs[feat_corr_i][0]\n",
    "            best_abs_corr = feats_corrs[feat_corr_i][1]\n",
    "\n",
    "            # Split the data according to the best feature\n",
    "            split_val = np.median(dataX[:, best_feat_i])\n",
    "\n",
    "            # Logical arrays for indexing\n",
    "            left_index = dataX[:, best_feat_i] <= split_val\n",
    "            right_index = dataX[:, best_feat_i] > split_val\n",
    "\n",
    "            # If we can split the data into two groups, then break out of the loop            \n",
    "            if len(np.unique(left_index)) != 1:\n",
    "                break\n",
    "            \n",
    "            avail_feats_for_split.remove(best_feat_i)\n",
    "            feat_corr_i += 1\n",
    "        \n",
    "        # If we complete the while loop and run out of features to split, return leaf\n",
    "        if len(avail_feats_for_split) == 0:\n",
    "            return np.array([-1, Counter(dataY).most_common(1)[0][0], np.nan, np.nan])\n",
    "\n",
    "        # Build left and right branches and the root                    \n",
    "        lefttree = self.__build_tree(dataX[left_index], dataY[left_index], dataX, dataY)\n",
    "        righttree = self.__build_tree(dataX[right_index], dataY[right_index], dataX, dataY)\n",
    "\n",
    "        # Set the starting row for the right subtree of the current root\n",
    "        if lefttree.ndim == 1:\n",
    "            righttree_start = 2 # The right subtree starts 2 rows down\n",
    "        elif lefttree.ndim > 1:\n",
    "            righttree_start = lefttree.shape[0] + 1\n",
    "        root = np.array([best_feat_i, split_val, 1, righttree_start])\n",
    "\n",
    "        return np.vstack((root, lefttree, righttree))\n",
    "    \n",
    "\n",
    "    def __tree_search(self, point, row):\n",
    "        \"\"\"A private function to be used with query. It recursively searches \n",
    "        the decision tree matrix and returns a predicted value for point\n",
    "        Parameters:\n",
    "        point: A numpy 1D array of test query\n",
    "        row: The row of the decision tree matrix to search\n",
    "    \n",
    "        Returns \n",
    "        pred: The predicted value\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the feature on the row and its corresponding splitting value\n",
    "        feat, split_val = self.tree[row, 0:2]\n",
    "        \n",
    "        # If splitting value of feature is -1, we have reached a leaf so return it\n",
    "        if feat == -1:\n",
    "            return split_val\n",
    "\n",
    "        # If the corresponding feature's value from point <= split_val, go to the left tree\n",
    "        elif point[int(feat)] <= split_val:\n",
    "            pred = self.__tree_search(point, row + int(self.tree[row, 2]))\n",
    "\n",
    "        # Otherwise, go to the right tree\n",
    "        else:\n",
    "            pred = self.__tree_search(point, row + int(self.tree[row, 3]))\n",
    "        \n",
    "        return pred\n",
    "\n",
    "\n",
    "    def addEvidence(self, dataX, dataY):\n",
    "        \"\"\"Add training data to learner\n",
    "        Parameters:\n",
    "        dataX: A numpy ndarray of X values of data to add\n",
    "        dataY: A numpy 1D array of Y training values\n",
    "        Returns: An updated tree matrix for DTLearner\n",
    "        \"\"\"\n",
    "\n",
    "        new_tree = self.__build_tree(dataX, dataY)\n",
    "\n",
    "        # If self.tree is currently None, simply assign new_tree to it\n",
    "        if self.tree is None:\n",
    "            self.tree = new_tree\n",
    "\n",
    "        # Otherwise, append new_tree to self.tree\n",
    "        else:\n",
    "            self.tree = np.vstack((self.tree, new_tree))\n",
    "        \n",
    "        # If there is only a single row, expand tree to a numpy ndarray for consistency\n",
    "        if len(self.tree.shape) == 1:\n",
    "            self.tree = np.expand_dims(self.tree, axis=0)\n",
    "        \n",
    "        if self.verbose:\n",
    "            self.get_learner_info()\n",
    "        \n",
    "        \n",
    "    def query(self, points):\n",
    "        \"\"\"Estimates a set of test points given the model we built\n",
    "        \n",
    "        Parameters:\n",
    "        points: A numpy ndarray of test queries\n",
    "        Returns: \n",
    "        preds: A numpy 1D array of the estimated values\n",
    "        \"\"\"\n",
    "\n",
    "        preds = []\n",
    "        for point in points:\n",
    "            preds.append(self.__tree_search(point, row=0))\n",
    "        return np.asarray(preds)\n",
    "\n",
    "\n",
    "    def get_learner_info(self):\n",
    "        print (\"Info about this Decision Tree Learner:\")\n",
    "        print (\"leaf_size =\", self.leaf_size)\n",
    "        if self.tree is not None:\n",
    "            print (\"tree shape =\", self.tree.shape)\n",
    "            print (\"tree as a matrix:\")\n",
    "            # Create a dataframe from tree for a user-friendly view\n",
    "            df_tree = pd.DataFrame(self.tree, columns=[\"factor\", \"split_val\", \"left\", \"right\"])\n",
    "            df_tree.index.name = \"node\"\n",
    "            print (df_tree)\n",
    "        else:\n",
    "            print (\"Tree has no data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some data to test the DTLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Decision Tree Learner\n",
      "\n",
      "Info about this Decision Tree Learner:\n",
      "leaf_size = 1\n",
      "Tree has no data\n",
      "\n",
      "Add data\n",
      "Info about this Decision Tree Learner:\n",
      "leaf_size = 1\n",
      "tree shape = (15, 4)\n",
      "tree as a matrix:\n",
      "      factor  split_val  left  right\n",
      "node                                \n",
      "0        2.0     9.9000   1.0    8.0\n",
      "1        2.0     9.2500   1.0    4.0\n",
      "2        0.0     0.7475   1.0    2.0\n",
      "3       -1.0     3.0000   NaN    NaN\n",
      "4       -1.0     4.0000   NaN    NaN\n",
      "5        0.0     0.6475   1.0    2.0\n",
      "6       -1.0     6.0000   NaN    NaN\n",
      "7       -1.0     5.0000   NaN    NaN\n",
      "8        0.0     0.4100   1.0    4.0\n",
      "9        0.0     0.2900   1.0    2.0\n",
      "10      -1.0     8.0000   NaN    NaN\n",
      "11      -1.0     6.0000   NaN    NaN\n",
      "12       0.0     0.6125   1.0    2.0\n",
      "13      -1.0     7.0000   NaN    NaN\n",
      "14      -1.0     5.0000   NaN    NaN\n",
      "\n",
      "Create another tree learner from an existing tree\n",
      "Info about this Decision Tree Learner:\n",
      "leaf_size = 1\n",
      "tree shape = (15, 4)\n",
      "tree as a matrix:\n",
      "      factor  split_val  left  right\n",
      "node                                \n",
      "0        2.0     9.9000   1.0    8.0\n",
      "1        2.0     9.2500   1.0    4.0\n",
      "2        0.0     0.7475   1.0    2.0\n",
      "3       -1.0     3.0000   NaN    NaN\n",
      "4       -1.0     4.0000   NaN    NaN\n",
      "5        0.0     0.6475   1.0    2.0\n",
      "6       -1.0     6.0000   NaN    NaN\n",
      "7       -1.0     5.0000   NaN    NaN\n",
      "8        0.0     0.4100   1.0    4.0\n",
      "9        0.0     0.2900   1.0    2.0\n",
      "10      -1.0     8.0000   NaN    NaN\n",
      "11      -1.0     6.0000   NaN    NaN\n",
      "12       0.0     0.6125   1.0    2.0\n",
      "13      -1.0     7.0000   NaN    NaN\n",
      "14      -1.0     5.0000   NaN    NaN\n",
      "Info about this Decision Tree Learner:\n",
      "leaf_size = 1\n",
      "Tree has no data\n",
      "Info about this Decision Tree Learner:\n",
      "leaf_size = 1\n",
      "tree shape = (7, 4)\n",
      "tree as a matrix:\n",
      "      factor  split_val  left  right\n",
      "node                                \n",
      "0        2.0    10.0000   1.0    6.0\n",
      "1        0.0     0.3200   1.0    2.0\n",
      "2       -1.0     6.0000   NaN    NaN\n",
      "3        0.0     0.6725   1.0    2.0\n",
      "4       -1.0     3.0000   NaN    NaN\n",
      "5       -1.0     5.0000   NaN    NaN\n",
      "6       -1.0     8.0000   NaN    NaN\n"
     ]
    }
   ],
   "source": [
    "print (\"This is a Decision Tree Learner\\n\")\n",
    "\n",
    "# Some data to test the DTLearner\n",
    "x0 = np.array([0.885, 0.725, 0.560, 0.735, 0.610, 0.260, 0.500, 0.320])\n",
    "x1 = np.array([0.330, 0.390, 0.500, 0.570, 0.630, 0.630, 0.680, 0.780])\n",
    "x2 = np.array([9.100, 10.900, 9.400, 9.800, 8.400, 11.800, 10.500, 10.000])\n",
    "x = np.array([x0, x1, x2]).T\n",
    "\n",
    "y = np.array([4.000, 5.000, 6.000, 5.000, 3.000, 8.000, 7.000, 6.000])\n",
    "\n",
    "\n",
    "# Create a tree learner from given train X and y\n",
    "dtl = DTLearner(verbose=True, leaf_size=1)\n",
    "print (\"\\nAdd data\")\n",
    "dtl.addEvidence(x, y)\n",
    "\n",
    "print (\"\\nCreate another tree learner from an existing tree\")\n",
    "dtl2 = DTLearner(tree=dtl.tree)\n",
    "\n",
    "# dtl2 should have the same tree as dtl\n",
    "assert np.any(dtl.tree == dtl2.tree)\n",
    "\n",
    "dtl2.get_learner_info()\n",
    "\n",
    "# Modify the dtl2.tree and assert that this doesn't affect dtl.tree\n",
    "dtl2.tree[0] = np.arange(dtl2.tree.shape[1])\n",
    "assert np.any(dtl.tree != dtl2.tree)\n",
    "\n",
    "# Query with dummy data\n",
    "dtl.query(np.array([[1, 2, 3], [0.2, 12, 12]]))\n",
    "\n",
    "# Another dataset to test that \"If the best feature doesn't split the data into two\n",
    "# groups, choose the second best one and so on; if none of the features does, return leaf\"\n",
    "x2 = np.array([\n",
    " [  0.26,    0.63,   11.8  ],\n",
    " [  0.26,    0.63,   11.8  ],\n",
    " [  0.32,    0.78,   10.   ],\n",
    " [  0.32,    0.78,   10.   ],\n",
    " [  0.32,    0.78,   10.   ],\n",
    " [  0.735,   0.57,    9.8  ],\n",
    " [  0.26,    0.63,   11.8  ],\n",
    " [  0.61,    0.63,    8.4  ]])\n",
    "\n",
    "y2 = np.array([ 8.,  8.,  6.,  6.,  6.,  5.,  8.,  3.])\n",
    "\n",
    "dtl = DTLearner(verbose=True)\n",
    "dtl.addEvidence(x2, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinRegLearner\n",
    "\n",
    "Linear Regression Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinRegLearner(object):  \n",
    "    \n",
    "    def __init__(self, verbose = False):\n",
    "        pass\n",
    "    \n",
    "    def addEvidence(self,dataX,dataY):  \n",
    "        \"\"\" \n",
    "        @summary: Add training data to learner  \n",
    "        @param dataX: X values of data to add  \n",
    "        @param dataY: the Y training values  \n",
    "        \"\"\"  \n",
    "        # slap on 1s column so linear regression finds a constant term \n",
    "        newdataX = np.ones([dataX.shape[0],dataX.shape[1]+1])  \n",
    "        newdataX[:,0:dataX.shape[1]]=dataX  \n",
    " \n",
    "        # build and save the model  \n",
    "        self.model_coefs, residuals, rank, s = np.linalg.lstsq(newdataX, dataY)  \n",
    " \n",
    "    def query(self,points): \n",
    "        \"\"\"  \n",
    "        @summary: Estimate a set of test points given the model we built.  \n",
    "        @param points: should be a numpy array with each row corresponding to a specific query.  \n",
    "        @returns the estimated values according to the saved model.  \n",
    "        \"\"\"  \n",
    "        return (self.model_coefs[:-1] * points).sum(axis = 1) + self.model_coefs[-1]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare two learners' rmse out of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_os_rmse(learner1, learner2, X, Y):  \n",
    "    # compute how much of the data is training and testing   \n",
    "    train_rows = int(math.floor(0.6* X.shape[0])) \n",
    "    test_rows = X.shape[0] - train_rows     \n",
    " \n",
    "    # separate out training and testing data  \n",
    "    train = np.random.choice(X.shape[0], size=train_rows, replace=False) \n",
    "    test = np.setdiff1d(np.array(range(X.shape[0])), train)  \n",
    "    trainX = X[train, :]\n",
    "    trainY = Y[train]  \n",
    "    testX = X[test, :]  \n",
    "    testY = Y[test] \n",
    "    \n",
    "    # train the learners \n",
    "    learner1.addEvidence(trainX, trainY) # train it  \n",
    "    learner2.addEvidence(trainX, trainY) # train it \n",
    "\n",
    "    # evaluate learner1 out of sample  \n",
    "    predY = learner1.query(testX) # get the predictions \n",
    "    rmse1 = math.sqrt(((testY - predY) ** 2).sum()/testY.shape[0])    \n",
    "\n",
    "    # evaluate learner2 out of sample \n",
    "    predY = learner2.query(testX) # get the predictions \n",
    "    rmse2 = math.sqrt(((testY - predY) ** 2).sum()/testY.shape[0])\n",
    "    return rmse1, rmse2 \n",
    "\n",
    "def test_code(): \n",
    "    # create two learners and get data  \n",
    "    lrlearner = LinRegLearner(verbose = False)   \n",
    "    dtlearner = DTLearner(verbose = False, leaf_size = 1)   \n",
    "    X, Y = best4LinReg()  \n",
    "\n",
    "    # compare the two learners  \n",
    "    rmseLR, rmseDT = compare_os_rmse(lrlearner, dtlearner, X, Y)  \n",
    "    print(\"rmseLR, rmseDT:\", rmseLR, rmseDT)\n",
    "    # share results    \n",
    "    print \n",
    "    print(\"best4LinReg() results\")\n",
    "    print(\"RMSE LR    : \", rmseLR)  \n",
    "    print(\"RMSE DT    : \", rmseDT)\n",
    "    if rmseLR < 0.9 * rmseDT:  \n",
    "        print(\"LR < 0.9 DT:  pass\")\n",
    "    else:  \n",
    "        print(\"LR >= 0.9 DT:  fail\")  \n",
    "    print  \n",
    "  \n",
    "    # get data that is best for a random tree  \n",
    "    lrlearner = LinRegLearner(verbose = False) \n",
    "    dtlearner = DTLearner(verbose = False, leaf_size = 1) \n",
    "    X, Y = best4DT()  \n",
    "\n",
    "    # compare the two learners  \n",
    "    rmseLR, rmseDT = compare_os_rmse(lrlearner, dtlearner, X, Y)  \n",
    "\n",
    "    # share results  \n",
    "    print  \n",
    "    print(\"best4RT() results\")\n",
    "    print(\"RMSE LR    : \", rmseLR)  \n",
    "    print(\"RMSE RT    : \", rmseDT)  \n",
    "    if rmseDT < 0.9 * rmseLR:  \n",
    "        print(\"DT < 0.9 LR:  pass\")  \n",
    "    else:    \n",
    "        print(\"DT >= 0.9 LR:  fail\") \n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner test\n",
    "Code that calls the two data set generating functions and tests them against the two learners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emi/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "/home/emi/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:3013: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  prob = _betai(0.5*df, 0.5, df/(df+t_squared))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmseLR, rmseDT: 1.4681229241792225e-15 0.6379561784404958\n",
      "best4LinReg() results\n",
      "RMSE LR    :  1.4681229241792225e-15\n",
      "RMSE DT    :  0.6379561784404958\n",
      "LR < 0.9 DT:  pass\n",
      "best4RT() results\n",
      "RMSE LR    :  4.1262487946016675\n",
      "RMSE RT    :  5.017815451510112\n",
      "DT >= 0.9 LR:  fail\n"
     ]
    }
   ],
   "source": [
    "test_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grade best4\n",
    "The grading script.\n",
    "\n",
    "For best4LinReg (1 test case):\n",
    "\n",
    "    * We will call best4LinReg 15 times, and select the 10 best datasets. For each successful test +5 points (total of 50 points)\n",
    "    * For each test case we will randomly select 60% of the data for training and 40% for testing.\n",
    "    * Success for each case is defined as: RMSE LinReg < RMSE DT * 0.9\n",
    "\n",
    "For best4DT (1 test case):\n",
    "\n",
    "    * We will call best4DT 15 times, and select the 10 best datasets. For each successful test +5 points (total of 50 points)\n",
    "    * For each test case we will randomly select 60% of the data for training and 40% for testing.\n",
    "    * Success for each case is defined as: RMSE DT < RMSE LinReg * 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent directory PATH for looking for modules,\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "import grading\n",
    "from grading.grading import Grader\n",
    "import pytest\n",
    "import os\n",
    "\n",
    "import traceback as tb\n",
    "from collections import namedtuple\n",
    "import time\n",
    "from functools import cmp_to_key\n",
    "\n",
    "seconds_per_test_case = 5\n",
    "\n",
    "max_points = 100.0 \n",
    "html_pre_block = True  # surround comments with HTML <pre> tag (for T-Square comments field)\n",
    "\n",
    "# Test cases\n",
    "Best4TestCase = namedtuple('Best4TestCase', ['description', 'group','max_tests','needed_wins','row_limits','col_limits','seed'])\n",
    "best4_test_cases = [\n",
    "    Best4TestCase(\n",
    "        description=\"Test Case 1: Best4LinReg\",\n",
    "        group=\"best4lr\",\n",
    "        max_tests=15,\n",
    "        needed_wins=10,\n",
    "        row_limits=(10,1001),\n",
    "        col_limits=(2,11),\n",
    "        seed=1489683274\n",
    "        ),\n",
    "    Best4TestCase(\n",
    "        description=\"Test Case 2: Best4DT\",\n",
    "        group=\"best4dt\",\n",
    "        max_tests=15,\n",
    "        needed_wins=10,\n",
    "        row_limits=(10,1001),\n",
    "        col_limits=(2,11),\n",
    "        seed=1489683274\n",
    "        )]\n",
    "\n",
    "def keyfunction(a, b):\n",
    "    return int((b[0]-b[1])-(a[0]-a[1]))\n",
    "\n",
    "\n",
    "def keyfunction_np_sign(a, b):\n",
    "    return int(np.sign((b[0]-b[1])-(a[0]-a[1])))\n",
    "\n",
    "# Test functon(s)\n",
    "@pytest.mark.parametrize(\"description,group,max_tests,needed_wins,row_limits,col_limits,seed\", best4_test_cases)\n",
    "def test_learners(description, group, max_tests, needed_wins, row_limits, col_limits, seed, grader):\n",
    "    \"\"\"Test data generation methods beat given learner.\n",
    "    Requires test description, test case group, and a grader fixture.\n",
    "    \"\"\"\n",
    "\n",
    "    points_earned = 0.0  # initialize points for this test case\n",
    "    incorrect = True\n",
    "    msgs = []\n",
    "    try:\n",
    "        dataX, dataY = None,None\n",
    "        same_dataX, same_dataY = None,None\n",
    "        diff_dataX, diff_dataY = None,None\n",
    "        betterLearner, worseLearner = None, None\n",
    "        \n",
    "        if group==\"best4dt\":\n",
    "            \n",
    "            dataX, dataY = run_with_timeout(best4DT,seconds_per_test_case,(),{'seed':seed})\n",
    "            same_dataX,same_dataY = run_with_timeout(best4DT,seconds_per_test_case,(),{'seed':seed})\n",
    "            diff_dataX,diff_dataY = run_with_timeout(best4DT,seconds_per_test_case,(),{'seed':seed+1})\n",
    "            betterLearner = DTLearner\n",
    "            worseLearner = LinRegLearner\n",
    "        elif group=='best4lr':\n",
    "            \n",
    "            dataX, dataY = run_with_timeout(best4LinReg,seconds_per_test_case,(),{'seed':seed})\n",
    "            same_dataX, same_dataY = run_with_timeout(best4LinReg,seconds_per_test_case,(),{'seed':seed})\n",
    "            diff_dataX, diff_dataY = run_with_timeout(best4LinReg,seconds_per_test_case,(),{'seed':seed+1})\n",
    "            betterLearner = LinRegLearner\n",
    "            worseLearner = DTLearner\n",
    "\n",
    "        num_samples = dataX.shape[0]\n",
    "        cutoff = int(num_samples*0.6)\n",
    "        worse_better_err = []\n",
    "        for run in range(max_tests):\n",
    "            permutation = np.random.permutation(num_samples)\n",
    "            train_X,train_Y = dataX[permutation[:cutoff]], dataY[permutation[:cutoff]]\n",
    "            test_X,test_Y = dataX[permutation[cutoff:]], dataY[permutation[cutoff:]]\n",
    "            better = betterLearner()\n",
    "            worse = worseLearner()\n",
    "            better.addEvidence(train_X,train_Y)\n",
    "            worse.addEvidence(train_X,train_Y)\n",
    "            better_pred = better.query(test_X)\n",
    "            worse_pred = worse.query(test_X)\n",
    "            better_err = np.linalg.norm(test_Y-better_pred)\n",
    "            worse_err = np.linalg.norm(test_Y-worse_pred)\n",
    "            worse_better_err.append( (worse_err,better_err) )\n",
    "        \n",
    "        worse_better_err.sort(key=cmp_to_key(keyfunction))\n",
    "        better_wins_count = 0\n",
    "        for worse_err,better_err in worse_better_err: \n",
    "            if better_err < 0.9*worse_err:\n",
    "                better_wins_count = better_wins_count+1\n",
    "                points_earned += 5.0\n",
    "            if better_wins_count >= needed_wins:\n",
    "                break\n",
    "        incorrect = False\n",
    "        if (dataX.shape[0] < row_limits[0]) or (dataX.shape[0]>row_limits[1]):\n",
    "            incorrect = True\n",
    "            msgs.append(\"    Invalid number of rows. Should be between {}, found {}\".format(row_limits,dataX.shape[0]))\n",
    "            points_earned = max(0,points_earned-20)\n",
    "        if (dataX.shape[1] < col_limits[0]) or (dataX.shape[1]>col_limits[1]):\n",
    "            incorrect = True\n",
    "            msgs.append(\"    Invalid number of columns. Should be between {}, found {}\".format(col_limits,dataX.shape[1]))\n",
    "            points_earned = max(0,points_earned-20)\n",
    "        if better_wins_count < needed_wins:\n",
    "            incorrect = True\n",
    "            msgs.append(\"    Better learner did not exceed worse learner. Expected {}, found {}\".format(needed_wins,better_wins_count))\n",
    "        if not(np.array_equal(same_dataY,dataY)) or not(np.array_equal(same_dataX,dataX)):\n",
    "            incorrect = True\n",
    "            msgs.append(\"    Did not produce the same data with the same seed.\\n\"+\\\n",
    "                        \"      First dataX:\\n{}\\n\".format(dataX)+\\\n",
    "                        \"      Second dataX:\\n{}\\n\".format(same_dataX)+\\\n",
    "                        \"      First dataY:\\n{}\\n\".format(dataY)+\\\n",
    "                        \"      Second dataY:\\n{}\\n\".format(same_dataY))\n",
    "            points_earned = max(0,points_earned-20)\n",
    "        if np.array_equal(diff_dataY,dataY) and np.array_equal(diff_dataX,dataX):\n",
    "            incorrect = True\n",
    "            msgs.append(\"    Did not produce different data with different seeds.\\n\"+\\\n",
    "                        \"      First dataX:\\n{}\\n\".format(dataX)+\\\n",
    "                        \"      Second dataX:\\n{}\\n\".format(diff_dataX)+\\\n",
    "                        \"      First dataY:\\n{}\\n\".format(dataY)+\\\n",
    "                        \"      Second dataY:\\n{}\\n\".format(diff_dataY))\n",
    "            points_earned = max(0,points_earned-20)  \n",
    "        \n",
    "        p1 = Grader()\n",
    "        if incorrect:\n",
    "            if group=='author':\n",
    "                raise (IncorrectOutput)\n",
    "            else:\n",
    "                inputs_str = \"    Residuals: {0}\".format(worse_better_err)\n",
    "                raise (Exception(\"Test failed on one or more output criteria.\\n  Inputs:\\n{0}\\n  Failures:\\n{1}\".format(inputs_str, \"\\n\".join(msgs))))\n",
    "        else:\n",
    "            if group != 'author':\n",
    "                avg_ratio = 0.0\n",
    "                worse_better_err.sort(key=cmp_to_key(keyfunction_np_sign))\n",
    "                \n",
    "                for we,be in worse_better_err[:10]:\n",
    "                    avg_ratio += (float(we) - float(be))\n",
    "                   \n",
    "                avg_ratio = avg_ratio/10.0\n",
    "                if group==\"best4dt\":\n",
    "                    p1 = Grader(np.array([avg_ratio,0]))\n",
    "                    p1.add_performance(p1)\n",
    "                else:\n",
    "                    p1 = Grader(np.array([0,avg_ratio]))\n",
    "                    p1.add_performance(p1)\n",
    "    except Exception as e:\n",
    "        # Test result: failed\n",
    "        msg = \"Description: {} (group: {})\\n\".format(description, group)\n",
    "        \n",
    "        # Generate a filtered stacktrace, only showing erroneous lines in student file(s)\n",
    "        tb_list = tb.extract_tb(sys.exc_info()[2])\n",
    "        for i in range(len(tb_list)):\n",
    "            row = tb_list[i]\n",
    "            tb_list[i] = (os.path.basename(row[0]), row[1], row[2], row[3])  # show only filename instead of long absolute path\n",
    "        tb_list = [row for row in tb_list if (row[0] == 'gen_data.py')]\n",
    "        if tb_list:\n",
    "            msg += \"Traceback:\\n\"\n",
    "            msg += ''.join(tb.format_list(tb_list))  # contains newlines\n",
    "        elif 'grading_traceback' in dir(e):\n",
    "            msg += \"Traceback:\\n\"\n",
    "            msg += ''.join(tb.format_list(e.grading_traceback))\n",
    "        msg += \"{}: {}\".format(e.__class__.__name__, str(e))\n",
    "\n",
    "        # Report failure result to grader, with stacktrace\n",
    "        p1.add_result(GradeResult(outcome='failed', points=points_earned, msg=msg))\n",
    "        raise\n",
    "    else:\n",
    "        # Test result: passed (no exceptions)\n",
    "        p1.add_result(GradeResult(outcome='passed', points=points_earned, msg=None))\n",
    "\n",
    "    \n",
    "    \n",
    "    return points_earned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emi/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "/home/emi/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:3013: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  prob = _betai(0.5*df, 0.5, df/(df+t_squared))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 1: Best4LinReg Total points:  50.0\n"
     ]
    }
   ],
   "source": [
    "# Test Case 1: Best4LinReg Total Points\n",
    "tp1 = test_learners(*best4_test_cases[0], best4_test_cases)\n",
    "print(\"Test Case 1: Best4LinReg Total points: \", tp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emi/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:3013: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  prob = _betai(0.5*df, 0.5, df/(df+t_squared))\n",
      "/home/emi/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Test failed on one or more output criteria.\n  Inputs:\n    Residuals: [(44.82441747649942, 38.68401197990367), (42.88202882480793, 38.145177488199074), (44.86270187834573, 39.157618521797545), (44.17586354251248, 39.105100166860886), (44.1335431873508, 41.22959163490233), (45.24516380180746, 42.36450773929684), (47.10844698414792, 43.50648764715951), (43.805401980529815, 40.234640112017395), (42.41153275509475, 41.0965715884463), (42.3981584496721, 41.82019917700367), (45.28576586094998, 44.962982669238976), (43.463850186715995, 42.43424203051986), (45.99809806594046, 44.715546469338534), (46.33465697698835, 47.20106126258009), (42.86958322217579, 45.479611929239255)]\n  Failures:\n    Better learner did not exceed worse learner. Expected 10, found 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-298-f9129723edb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test Case 2: Best4LinReg Total Points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_learners\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbest4_test_cases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest4_test_cases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test Case 2: Best4DT Total points: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-297-09aa50ee0c9a>\u001b[0m in \u001b[0;36mtest_learners\u001b[0;34m(description, group, max_tests, needed_wins, row_limits, col_limits, seed, grader)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0minputs_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"    Residuals: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworse_better_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test failed on one or more output criteria.\\n  Inputs:\\n{0}\\n  Failures:\\n{1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'author'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Test failed on one or more output criteria.\n  Inputs:\n    Residuals: [(44.82441747649942, 38.68401197990367), (42.88202882480793, 38.145177488199074), (44.86270187834573, 39.157618521797545), (44.17586354251248, 39.105100166860886), (44.1335431873508, 41.22959163490233), (45.24516380180746, 42.36450773929684), (47.10844698414792, 43.50648764715951), (43.805401980529815, 40.234640112017395), (42.41153275509475, 41.0965715884463), (42.3981584496721, 41.82019917700367), (45.28576586094998, 44.962982669238976), (43.463850186715995, 42.43424203051986), (45.99809806594046, 44.715546469338534), (46.33465697698835, 47.20106126258009), (42.86958322217579, 45.479611929239255)]\n  Failures:\n    Better learner did not exceed worse learner. Expected 10, found 4"
     ]
    }
   ],
   "source": [
    "# Test Case 2: Best4LinReg Total Points\n",
    "tp2 = test_learners(*best4_test_cases[1], best4_test_cases)\n",
    "print(\"Test Case 2: Best4DT Total points: \", tp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WARNING\n",
    "\n",
    "I don't know whether the exception is correst or not. I won't spend more time testing. Maybe in the future I'll try it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
