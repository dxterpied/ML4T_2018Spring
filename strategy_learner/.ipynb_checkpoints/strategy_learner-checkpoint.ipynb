{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "toc-hr-collapsed": false
   },
   "source": [
    "# Strategy Learner\n",
    "ML for trading Udacity Course exercise\n",
    "\n",
    "More info:\n",
    "https://quantsoftware.gatech.edu/Strategy_learner\n",
    "\n",
    "A transcription of the Udacity Course lectures can be find on https://docs.google.com/document/d/1ELqlnuTSdc9-MDHOkV0uvSY4RmI1eslyQlU9DgOY_jc/edit?usp=sharing\n",
    "\n",
    "Kairoart 2018\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "In this project you will design a learning trading agent. You must draw on the learners you have created so far in the course. Your choices are:\n",
    "\n",
    "    1. Regression or classification-based learner: Create a strategy using your Random Forest learner. Suggestions if you follow this approach: Classification_Trader_Hints. Important note, if you choose this method, you must set the leaf_size for your learner to 5 or greater. This is to avoid degenerate overfitting in-sample.\n",
    "    2. Reinforcement Learner-based approach: Create a Q-learning-based strategy using your Q-Learner. Read the Classification_Trader_Hints first, because many of the ideas there are relevant for the Q trader, then see Q_Trader_Hints\n",
    "    3. Optimization-based learner: Create a scan-based strategy using an optimizer. Read the Classification_Trader_Hints first, because many of the ideas there are relevant for the Opto trader, then see Opto_Trader_Hints\n",
    "\n",
    "Regardless of your choice above, your learner should work in the following way:\n",
    "\n",
    "    * In the training phase (e.g., addEvidence()) your learner will be provided with a stock symbol and a time period. It should use this data to learn a strategy. For instance, for a regression-based learner it will use this data to make predictions about future price changes.\n",
    "    * In the testing phase (e.g., testPolicy()) your learner will be provided a symbol and a date range. All learning should be turned OFF during this phase.\n",
    "\n",
    "\n",
    "If the date range is the same as used for the training, it is an in-sample test. Otherwise it is an out-of-sample test. Your learner should return a trades dataframe like it did in the last project. Here are some important requirements: Your testPolicy() method should be much faster than your addEvidence() method. The timeout requirements (see rubric) will be set accordingly. Multiple calls to your testPolicy() method should return exactly the same result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "* Devise numerical/technical indicators to evaluate the state of a stock on each day.\n",
    "* Build a strategy learner based on one of the learners described above that uses the indicators.\n",
    "* Test/debug the strategy learner on specific symbol/time period problems.\n",
    "* Write a report describing your learning strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Details, Dates and Rules\n",
    "\n",
    "* For your report, trade only the symbol JPM. This will enable us to more easily compare results. We will test your learner with other symbols as well.\n",
    "* You may use data from other symbols (such as SPY) to inform your strategy.\n",
    "* The in sample/development period is January 1, 2008 to December 31 2009.\n",
    "* The out of sample/testing period is January 1, 2010 to December 31 2011.\n",
    "* Starting cash is $100,000.\n",
    "* Allowable positions are: 1000 shares long, 1000 shares short, 0 shares.\n",
    "* Benchmark: The performance of a portfolio starting with $100,000 cash, investing in 1000 shares of the symbol in use and holding that position. Include transaction costs.\n",
    "* There is no limit on leverage.\n",
    "* Transaction costs: Commission will always be $0.00, Impact may vary, and will be passed in as a parameter to the learner.\n",
    "* Minimize use of herrings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
